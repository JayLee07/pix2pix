{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import parser\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from model_utils import *\n",
    "from image_utils import *\n",
    "from networks import *\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, time, pickle\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from image_utils import is_image, load_img\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def argument():\n",
    "#     parser = argparse.ArgumentParser(description='pix2pix-PyTorch-implementation')\n",
    "#     parser.add_argument('--dataset', required=True, default='facades')\n",
    "#     parser.add_argument('--trainBatchSize', type=int, default=1, help='training batch size')\n",
    "#     parser.add_argument('--testBatchSize', type=int, default=1, help='testing batch size')\n",
    "#     parser.add_argument('--maxepochs', type=int, default=200, help='number of epochs')\n",
    "#     parser.add_argument('--ch_in', type=int, default=3, help='input image channels')\n",
    "#     parser.add_argument('--ch_out', type=int, default=3, help='output image channels')\n",
    "#     parser.add_argument('--ngf', type=int, default=64, help='generator filters')\n",
    "#     parser.add_argument('--ndf', type=int, default=64, help='discriminator filters')\n",
    "#     parser.add_argument('--lrD', type=float, default=0.0002, help='Learning Rate D')\n",
    "#     parser.add_argument('--lrG', type=float, default=0.0002, help='Learning Rate G')\n",
    "#     parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "#     parser.add_argument('--cuda', action='store_true', default=True, help='use cuda?')\n",
    "#     parser.add_argument('--threads', type=int, default=4, help='number of threads for data loader to use')\n",
    "#     parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')\n",
    "#     parser.add_argument('--lamb', type=int, default=10, help='weight on L1 term in objective')\n",
    "#     parser.add_argument('--save_dir', type=str, default='result')\n",
    "#     parser.add_argument('--model', type=str, default='pix2pix')\n",
    "#     parser.add_argument('--model_type_D', type=str, default='n_layer')\n",
    "#     parser.add_argument('--model_type_G', type=str, default='resnet_9blocks')\n",
    "#     parser.add_argument('--norm_type', type=str, default='instance')\n",
    "#     parser.add_argument('--use_dropout', type=bool, default='False')\n",
    "#     parser.add_argument('--init_type', type=str, default='normal')\n",
    "    \n",
    "#     opt = parser.parse_args()\n",
    "#     return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    def __init__(self):\n",
    "        self.dataset = 'facades'\n",
    "        self.trainBatchSize=1\n",
    "        self.testBatchSize=1\n",
    "        self.maxepoch=200\n",
    "        self.ch_in=3\n",
    "        self.ch_out=3\n",
    "        self.ngf=64\n",
    "        self.ndf=64\n",
    "        self.lrD=1e-6\n",
    "        self.lrG=1e-5\n",
    "        self.beta1=0.5\n",
    "        self.cuda=True\n",
    "        self.threads=4\n",
    "        self.seed=123\n",
    "        self.lamb=10\n",
    "        self.save_dir='result'\n",
    "        self.model='pix2pix'\n",
    "        self.model_type_D='n_layer'\n",
    "        self.model_type_G='resnet_9blocks'\n",
    "        self.norm_type='instance'\n",
    "        self.use_dropout=False\n",
    "        self.init_type='normal'\n",
    "        self.use_sigmoid=True\n",
    "args = arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class pix2pix(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.D = define_D(args.ch_in, args.ndf, args.model_type_D, 3, args.norm_type, args.use_sigmoid, args.init_type, [0])\n",
    "        self.G = define_G(args.ch_in, args.ch_out, args.ngf, args.model_type_G, args.norm_type, args.use_dropout, args.init_type, [0])\n",
    "        self.optim_D = torch.optim.Adam(params=self.D.parameters(), lr = self.args.lrD)\n",
    "        self.optim_G = torch.optim.Adam(params=self.G.parameters(), lr = self.args.lrG)\n",
    "        trn_dset, tst_dset = get_train_set('/data/jehyuk/imgdata/datasets/facades/'), get_test_set('/data/jehyuk/imgdata/datasets/facades/')\n",
    "        self.sampleA, self.sampleB = tst_dset[0][0].unsqueeze(dim=0).cuda(), tst_dset[0][1].unsqueeze(dim=0).cuda()\n",
    "        self.trn_loader = DataLoader(dataset=trn_dset, num_workers=2, batch_size=1, shuffle=True)\n",
    "        self.tst_loader = DataLoader(dataset=tst_dset, num_workers=2, batch_size=1, shuffle=False)\n",
    "\n",
    "        self.bce_loss, self.mse_loss, self.L1_loss = nn.BCELoss().cuda(), nn.MSELoss().cuda(), nn.L1Loss().cuda()\n",
    "        self.bce_true_gan_loss, self.bce_fake_gan_loss = GANLoss(False, True).cuda(), GANLoss(False, False).cuda()\n",
    "        self.ls_true_gan_loss, self.ls_fake_gan_loss = GANLoss(True, True).cuda(), GANLoss(True, False).cuda()\n",
    "        \n",
    "    def train(self):\n",
    "        self.loss_dict = dict()\n",
    "        self.loss_dict['G_loss'], self.loss_dict['D_fake_loss'], self.loss_dict['D_real_loss'] = list(), list(), list()\n",
    "        print('------------------Start training------------------')\n",
    "        for epoch in range(self.args.maxepoch):\n",
    "            self.D.train()\n",
    "            print(\">>>>Epoch: {}\".format(epoch+1))\n",
    "            start_time = time.time()\n",
    "            for iter_num, batch in enumerate(self.trn_loader):\n",
    "                real_a, real_b = batch[0].cuda(), batch[1].cuda()\n",
    "                fake_b = self.G.forward(real_a)\n",
    "                \n",
    "                ###### Train D ######\n",
    "                self.optim_D.zero_grad()\n",
    "                # Train with fake pair\n",
    "                fake_ab = torch.cat((real_a, fake_b), 2)\n",
    "                D_fake_ab = self.D.forward(fake_ab.detach()) # Make compute gradient not to be calculated\n",
    "                D_fake_loss = self.bce_fake_gan_loss(D_fake_ab)\n",
    "                #Train with real pair\n",
    "                real_ab = torch.cat((real_a, real_b), 2)\n",
    "                D_real_ab = self.D.forward(real_ab.detach())\n",
    "                D_real_loss = self.ls_true_gan_loss(D_real_ab)\n",
    "                \n",
    "                D_loss = 0.5*(D_fake_loss + D_real_loss)\n",
    "                D_loss.backward()\n",
    "                self.optim_D.step()\n",
    "                \n",
    "                ###### Train G ######\n",
    "                self.D.eval()\n",
    "                self.optim_G.zero_grad()\n",
    "                # Train with fake pair. G must fake the Discriminator\n",
    "                fake_ab = torch.cat((real_a, fake_b), 2)\n",
    "                D_fake_ab = self.D.forward(fake_ab)\n",
    "                G_fake_loss = self.ls_fake_gan_loss(D_fake_ab)\n",
    "                # G(A) = B\n",
    "                L1_loss = self.L1_loss(fake_b, real_b) * args.lamb\n",
    "                \n",
    "                G_loss = G_fake_loss + L1_loss\n",
    "                G_loss.backward()\n",
    "                self.optim_G.step()\n",
    "                self.loss_dict['G_loss'] = G_loss\n",
    "                self.loss_dict['D_fake_loss'] = D_fake_loss\n",
    "                self.loss_dict['D_real_loss'] = D_real_loss\n",
    "                \n",
    "            print(\"In epoch: {}, D_fake_loss: {:.4f}, D_real_loss: {:.4f}, G_loss: {:.4f}\".format(epoch+1, D_fake_loss, D_real_loss, G_loss))\n",
    "            self.save_results(epoch, self.sampleA, self.sampleB)\n",
    "        self.save_model()\n",
    "            \n",
    "    def save_results(self, epoch, realA, realB):\n",
    "        #save result img file\n",
    "        result_dir = self.args.save_dir + '/logs/' + self.args.model + '/' + self.args.dataset\n",
    "        exp_config = \"ngf_{}_ndf_{}_lambda_{}_norm_{}\".format(self.args.ngf, self.args.ndf, self.args.lamb, self.args.norm_type)\n",
    "        result_dir = os.path.join(result_dir, exp_config)\n",
    "        \n",
    "        self.G.eval()\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        fake_filename = result_dir + '/epoch%03d' %epoch + '.png'\n",
    "        fakeB = self.G.forward(realA)\n",
    "        results = torch.cat((realA, fakeB, realB), 2)\n",
    "        results_img = tensor2img(results)\n",
    "        save_image(results_img, fake_filename)\n",
    "\n",
    "    def save_model(self):\n",
    "        #save trained models\n",
    "        model_dir = self.args.save_dir + '/' + self.args.model + '/' + self.args.dataset\n",
    "        exp_config = \"ngf_{}_ndf_{}_lambda_{}_norm_{}\".format(self.args.ngf, self.args.ndf, self.args.lamb, self.args.norm_type)\n",
    "        model_dir = os.path.join(model_dir, exp_config)\n",
    "        \n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        torch.save(self.G.state_dict(), os.path.join(model_dir, 'G.pkl'))\n",
    "        torch.save(self.D.state_dict(), os.path.join(model_dir, 'D.pkl'))\n",
    "        with open(os.path.join(model_dir, 'loss_dict'), 'wb') as f:\n",
    "            pickle.dump(self.loss_dict, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        model_dir = self.args.save_dir + '/' + self.args.model + '/' + self.args.dataset\n",
    "        exp_config = \"ngf_{}_ndf_{}_lambda_{}_norm_{}\".format(self.args.ngf, self.args.ndf, self.args.lamb, self.args.norm_type)\n",
    "        model_dir = os.path.join(model_dir, exp_config)\n",
    "        \n",
    "        self.G.load_state_dict(torch.load(os.path.join(model_dir, 'G.pkl')))\n",
    "        self.D.load_state_dict(torch.load(os.path.join(model_dir, 'D.pkl')))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pix2pix(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Start training------------------\n",
      ">>>>Epoch: 1\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
